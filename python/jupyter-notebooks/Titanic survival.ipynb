{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Titanic survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sqlContext.read.csv('file:///E:/Kapil/software-study/Big_Data_NoSql/machine-learning/train.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparing features and adding \n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier\n",
    "##Try to collect other features\n",
    "featureColumns=['Pclass','Sex','SibSp','Parch']\n",
    "##check stratergies instead of skipping null values.This will improve the model\n",
    "strInds=[StringIndexer(inputCol=c,outputCol='stringFeature_'+c,handleInvalid='skip') for c in featureColumns]\n",
    "strInds.append(StringIndexer(inputCol='Survived',outputCol='Feature_Survived'))\n",
    "\n",
    "##Assembling feature vector from feature columns\n",
    "ve=VectorAssembler()\n",
    "ve.setInputCols(['stringFeature_'+c for c in featureColumns])\n",
    "ve.setOutputCol('Features')\n",
    "##Using decision tree classfier\n",
    "lr= DecisionTreeClassifier()\n",
    "lr.setMaxBins(200)\n",
    "lr.setLabelCol(\"Feature_Survived\").setFeaturesCol(\"Features\")\n",
    "\n",
    "strInds.append(ve)\n",
    "strInds.append(lr)\n",
    "\n",
    "##Ml pipeline\n",
    "pipeline=Pipeline()\n",
    "pipeline.setStages(value=strInds)\n",
    "##Training dataset\n",
    "pipelinemodel=pipeline.fit(dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predicting using testing dataset\n",
    "testData=sqlContext.read.csv('file:///E:/Kapil/software-study/Big_Data_NoSql/machine-learning/test.csv',header=True)\n",
    "predictions=pipelinemodel.transform(testData)\n",
    "predicted=predictions.select(['PassengerId','Prediction'])\n",
    "##Saving predrictions to file\n",
    "predicted.write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"file:///E:/Kapil/software-study/Big_Data_NoSql/machine-learning/predicted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
